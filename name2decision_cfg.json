{
    "megatron/core/rl_trainer.py(1574): train_loop": "b",
    "megatron/core/rl_trainer.py(1194): train_step": "b",
    "megatron/core/rl_trainer.py(359): _backload_weights": "g",
    "megatron/core/rl_trainer.py(1019): generate_micro_batches_and_compute_rewards_and_references": "b",
    "megatron/core/rl_trainer.py(796): run_generation": "g",
    "megatron/core/rl_trainer.py(2020): _prepare_actor_weights_for_inference_gathering_from_pipeline_parallel": "g",
    "cudaLaunchKernel": "k",
    "torch/distributed/distributed_c10d.py(142): wrapper": "b",
    "torch/distributed/distributed_c10d.py(2501): scatter_object_list": "g",
    "torch/distributed/distributed_c10d.py(2396): broadcast_object_list": "g",
    "aten::to": "k",
    "nn.Module: InferenceEngine": "g",
    "cudaMemcpyAsync": "k",
    "aten::add": "k",
    "aten::item": "k",
    "aten::arange": "k",
    "megatron/timers.py(375): stop": "g",
    "megatron/core/rl_trainer.py(935): shift_left": "g",
    "aten::slice": "k",
    "megatron/timers.py(370): start": "g",
    "torch/distributed/distributed_c10d.py(2194): all_gather_object": "g",
    "megatron/core/rl_trainer.py(997): forward_and_save": "k .",
    "torch/distributed/distributed_c10d.py(1835): all_reduce": "k",
    "megatron/core/rl_trainer.py(1144): <genexpr>": "p",
    "aten::sum": "p",
    "megatron/core/rl_trainer.py(1148): <genexpr>": "p",
    "aten::div": "p",
    "megatron/core/rl_trainer.py(1152): <genexpr>": "p",
    "megatron/core/rl_trainer.py(114): _normalize_advantage": "p",
    "megatron/core/rl_trainer.py(1174): <genexpr>": "p",
    "megatron/core/rl_trainer.py(354): _offload_weights": "g",
    "megatron/core/rl_trainer.py(487): _backload_optimizer_state": "g",
    "megatron/core/rl_trainer.py(1196): get_mask_avg_divisor": "k",
    "megatron/core/rl_trainer.py(1969): forward_backward": "k .",
    "megatron/core/rl_trainer.py(583): after_train_step": "b",
    "megatron/schedules.py(243): forward_backward_pipelining_with_interleaving": "k .",
    "megatron/core/rl_trainer.py(574): before_train_step": "b",
    "megatron/core/rl_trainer.py(431): _offload_optimizer_state": "g",
    "megatron/schedules.py(304): forward_step_helper": "k .",
    "megatron/p2p_communication.py(461): send_forward_recv_forward": "k .",
    "aten::empty": "p",
    "megatron/core/parallel_state.py(373): is_pipeline_last_stage": "p",
    "megatron/p2p_communication.py(370): recv_backward": "k .",
    "megatron/p2p_communication.py(480): send_backward_recv_backward": "k. ",
    "torch/utils/_contextlib.py(112): decorate_context": "p",
    "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward": "g",
    "aten::matmul": "g",
    "megatron/model/fused_rms_norm.py(63): backward": "g",
    "autograd::engine::evaluate_function: FlashAttnVarlenFuncBackward": "g",
    "autograd::engine::evaluate_function: ExpandBackward": "g",
    "autograd::engine::evaluate_function: RMSNormKernelFunctionBackward": "g",
    "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad": "g",
    "autograd::engine::evaluate_function: MulBackward": "g",
    "autograd::engine::evaluate_function: SiluBackward": "g",
    "autograd::engine::evaluate_function: SplitBackward": "g",
    "autograd::engine::evaluate_function: PermuteBackward": "g",
    "autograd::engine::evaluate_function: _ReduceFromModelParallelRegionBackward": "g",
    "cudaMemsetAsync": "g",
    "MulBackward0": "g",
    "autograd::engine::evaluate_function: ViewBackward": "g",
    "LinearWithGradAccumulationAndAsyncCommunicationBackward": "g",
    "torch/autograd/function.py(264): apply": "b",
    "megatron/core/tensor_parallel/layers.py(506): backward": "g",
    "aten::mul": "g",
    "autograd::engine::evaluate_function: CloneBackward": "g",
    "SiluBackward0": "g",
    "autograd::engine::evaluate_function: ReshapeAliasBackward": "g",
    "autograd::engine::evaluate_function: torch::autograd::CopySlices": "g",
    "aten::embedding_backward": "g",
    "optimus/flash_attn_interface.py(322): backward": "g",
    "aten::new_empty_strided": "g",
    "IndexPutBackward0": "g",
    "autograd::engine::evaluate_function: EmbeddingBackward": "g",
    "aten::embedding_dense_backward": "g",
    "autograd::engine::evaluate_function: UnsqueezeBackward": "g",
    "autograd::engine::evaluate_function: SqueezeBackward": "g",
    "torch::autograd::CopySlices": "g",
    "SqueezeBackward1": "g",
    "autograd::engine::evaluate_function: AddBackward": "g",
    "aten::permute": "g",
    "aten::empty_strided": "g",
    "FlashAttnVarlenFuncBackward": "g",
    "aten::mm": "g",
    "megatron/core/tensor_parallel/layers.py(511): get_grad_weight": "b",
    "ExpandBackward0": "g",
    "aten::copy_": "g",
    "aten::clone": "g",
    "PermuteBackward0": "g",
    "_ReduceFromModelParallelRegionBackward": "g",
    "ViewBackward0": "g",
    "aten::transpose": "g",
    "autograd::engine::evaluate_function: SplitWithSizesBackward": "g",
    "autograd::engine::evaluate_function: TransposeBackward": "g",
    "megatron/model/distributed.py(176): param_hook": "g",
    "EmbeddingBackward0": "g",
    "autograd::engine::evaluate_function: MakeViewlessTensorBackward": "g",
    "RMSNormKernelFunctionBackward": "g",
    "aten::t": "g",
    "aten::empty_like": "g",
    "aten::reshape": "g",
    "TransposeBackward0": "g",
    "aten::cat": "g",
    "aten::detach": "g",
    "MakeViewlessTensorBackward": "g",
    "SplitBackward0": "g",
    "aten::unsqueeze": "g",
    "torch::autograd::AccumulateGrad": "g",
    "aten::as_strided": "g",
    "aten::add_": "g",
    "aten::silu_backward": "g",
    "megatron/core/rl_trainer.py(2114): _normalize_advantage": "g",
    "megatron/optimizer/optimizer.py(278): reduce_model_grads": "g",
    "megatron/optimizer_param_scheduler.py(119): step": "g",
    "megatron/optimizer/optimizer.py(542): zero_grad": "g",
    "aten::_local_scalar_dense": "p",
    "megatron/model/distributed.py(186): zero_grad_buffer": "g",
    "megatron/model/distributed.py(201): allreduce_gradients": "k .",
    "c10d::allreduce_": "k ."
}